{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from keras.utils import to_categorical\n",
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from math import isnan\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nan = df.iloc[ : ,1 : - 1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train_nan.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "X_test_nan = df_test.iloc[ : ,1 : ]\n",
    "X_test_nan.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_nan = pd.DataFrame(np.concatenate((X_train_nan, X_test_nan)))\n",
    "print(X_all_nan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = np.array(y)\n",
    "[print(len(y_arr[np.where(y_arr == i)])) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_all_nan.corr(method = 'pearson')\n",
    "f, ax = plt.subplots(figsize=(22, 18))\n",
    "cmap = sns.diverging_palette(10, 275, as_cmap = True)\n",
    "sns.heatmap(corr, cmap = cmap, square = True,\n",
    "            linewidths = 0.5, cbar_kws = {\"shrink\": 0.5}, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(X, y, j):\n",
    "    X_to_plot = X.iloc[:,j]\n",
    "    plt.plot(X_to_plot, y, 'b+')\n",
    "    plt.axvline(x = X_to_plot.quantile(0.1), color = 'r')\n",
    "    plt.axvline(x = X_to_plot.quantile(0.90), color = 'r')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class(X_train_nan, y_arr, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_nan_scaled = (X_all_nan - X_all_nan.mean()) / X_all_nan.std()\n",
    "X_all_nan_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all_nan_scaled.fillna(X_all_nan_scaled.mean())\n",
    "X_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_factors = np.zeros((len(X_all_nan), len(X_all_nan.columns)), dtype = int)\n",
    "for i in range(len(X_all_nan)):\n",
    "    for j in range(len(X_all_nan.columns)):\n",
    "        if isnan(X_all_nan.iloc[i,j]):\n",
    "            nan_factors[i,j] = int(1)\n",
    "\n",
    "nan_factors = pd.DataFrame(nan_factors)\n",
    "nan_factors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_factors.columns = nan_factors.columns + 110\n",
    "print(nan_factors.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_expanded = pd.concat([X_all, nan_factors], axis = 1)\n",
    "X_all_expanded.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all_expanded.loc[ : 49999, : ]\n",
    "X_test = X_all_expanded.loc[50000 : , : ]\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_class(X, y, i, j):\n",
    "    X_to_plot = np.array(X.iloc[:,j])\n",
    "    X_to_plot = X_to_plot[np.where(y == i)]\n",
    "    plt.hist(X_to_plot)\n",
    "    plt.show()\n",
    "hist_class(X, y, 6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32, 12))\n",
    "sns.heatmap(X.iloc[:,90:110].corr(method='pearson'), vmin=-1, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32, 12))\n",
    "sns.pairplot(df[['90', '52', 'label']], hue = 'label')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "discrete_features = X.dtypes == int\n",
    "\n",
    "def make_mi_scores(X_mi, y, discrete_features):\n",
    "    mi_scores = mutual_info_classif(X_mi, y, discrete_features = discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name = \"MI Scores\", index = X_mi.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending = False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y, discrete_features = discrete_features)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending = True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores, color = 'steelblue', edgecolor = 'black')\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "plt.figure(dpi = 100, figsize = (10, 50))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KF = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "KF.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train, ys_train, Xs_val, ys_val = [], [], [], []\n",
    "\n",
    "for train_index, val_index in KF.split(X, y):\n",
    "    Xs_train.append(X.iloc[train_index,:])\n",
    "    ys_train.append(y[train_index])\n",
    "    Xs_val.append(X.iloc[val_index,:])\n",
    "    ys_val.append(y[val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB = GaussianNB()\n",
    "\n",
    "RF = RandomForestClassifier(bootstrap = False, \\\n",
    "                             min_samples_split = 2, \\\n",
    "                             n_estimators = 500, n_jobs = - 1, \\\n",
    "                             random_state = 1, \\\n",
    "                             class_weight = 'balanced')\n",
    "\n",
    "LR = LogisticRegression(penalty = 'l1', n_jobs = - 1, \\\n",
    "                              C = 0.2, dual = False, solver = 'saga', \\\n",
    "                              multi_class = 'multinomial', \\\n",
    "                              random_state = 1, \\\n",
    "                              class_weight = 'balanced')\n",
    "\n",
    "ADA = AdaBoostClassifier(DecisionTreeClassifier(random_state = 1, class_weight = 'balanced'), \n",
    "                         n_estimators = 500, learning_rate = 0.5, random_state = 1)\n",
    "\n",
    "BC = BaggingClassifier(DecisionTreeClassifier(random_state = 1, class_weight = 'balanced'), \n",
    "                       n_estimators = 500, bootstrap = False, n_jobs = - 1, random_state = 1)\n",
    "\n",
    "ETC = ExtraTreesClassifier(bootstrap = False, \\\n",
    "                             min_samples_split = 2, \\\n",
    "                             n_estimators = 500, n_jobs = - 1, \\\n",
    "                             random_state = 500, class_weight = 'balanced')\n",
    "\n",
    "GB = GradientBoostingClassifier(n_estimators = 500, random_state = 1, validation_fraction = 0.25)\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors = 10, weights = 'distance', n_jobs = - 1)\n",
    "\n",
    "MLP = MLPClassifier(learning_rate_init = 0.0001, hidden_layer_sizes = (50, 20, 1), \\\n",
    "                   validation_fraction = 0.25, random_state = 1, max_iter=500, \\\n",
    "                   early_stopping = True, n_iter_no_change = 50, tol = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = StackingClassifier(estimators = [('GNB', GNB), \\\n",
    "\n",
    "                                ('RF', RF), \\\n",
    "                                \n",
    "                                ('LR', LR), \\\n",
    "                                      \n",
    "                                ('ADA', ADA), \\\n",
    "                                \n",
    "                                ('BC', BC), \\\n",
    "                                \n",
    "                                ('ETC', ETC), \\\n",
    "                                \n",
    "                                ('GB', GB), \\\n",
    "                                                                \n",
    "                                ('KNN', KNN), \\\n",
    "                                      \n",
    "                                ('MLP', MLP)], n_jobs = 1, \\\n",
    "                        final_estimator = RandomForestClassifier(bootstrap = False, \\\n",
    "                                                                 min_samples_split = 2, \\\n",
    "                                                                 n_estimators = 500, \\\n",
    "                                                                 random_state = 1, \\\n",
    "                                                                 class_weight = 'balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, y, model, pl):\n",
    "    print(pl)\n",
    "    print(model)\n",
    "    model.fit(X, y)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [GNB, RF, LR, ADA, BC, ETC, GB, KNN, MLP, SC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = [fit_model(Xs_train[0], ys_train[0], m, pl = 0) for m in all_models]\n",
    "models_2 = [fit_model(Xs_train[1], ys_train[1], m, pl = 1) for m in all_models]\n",
    "models_3 = [fit_model(Xs_train[2], ys_train[2], m, pl = 2) for m in all_models]\n",
    "models_4 = [fit_model(Xs_train[3], ys_train[3], m, pl = 3) for m in all_models]\n",
    "models_5 = [fit_model(Xs_train[4], ys_train[4], m, pl = 4) for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [[], [], [], [], [], [], [], [], []]\n",
    "models_agg = [models_1, models_2, models_3, models_4, models_5]\n",
    "for i in range(5):\n",
    "    preds[0].append(models_agg[i][0].predict_proba(Xs_val[i]))\n",
    "    preds[1].append(models_agg[i][1].predict_proba(Xs_val[i]))\n",
    "    preds[2].append(models_agg[i][2].predict_proba(Xs_val[i]))\n",
    "    preds[3].append(models_agg[i][3].predict_proba(Xs_val[i]))\n",
    "    preds[4].append(models_agg[i][4].predict_proba(Xs_val[i]))\n",
    "    preds[5].append(models_agg[i][5].predict_proba(Xs_val[i]))\n",
    "    preds[6].append(models_agg[i][6].predict_proba(Xs_val[i]))\n",
    "    preds[7].append(models_agg[i][7].predict_proba(Xs_val[i]))\n",
    "    preds[8].append(models_agg[i][8].predict_proba(Xs_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(w):\n",
    "    prob_pred = preds\n",
    "    y_true = ys_val\n",
    "    w_hat = w\n",
    "    prob_pred = np.array(prob_pred)\n",
    "    prob_w = np.array([prob_pred[k] * w_hat[k] for k in range(len(prob_pred))])\n",
    "    prob_agg = np.sum(prob_w, axis = 0)\n",
    "    y_hat = np.argmax(prob_agg, axis = 2)\n",
    "    all_score = np.array([metrics.accuracy_score(y_true[k], y_hat[k]) for k in range(len(y_true))])\n",
    "    av_score = np.mean(all_score, 0)\n",
    "    return av_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dict1 = {\n",
    "    \"obj_func\": predict_y,\n",
    "    \"lb\": [- 10, ] * 9,\n",
    "    \"ub\": [10, ] * 9,\n",
    "    \"minmax\": \"max\",\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mealpy.bio_based import SMA\n",
    "from mealpy.evolutionary_based import DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DE.JADE(problem_dict1, epoch = 1000, pop_size = 100, miu_f = 0.5, miu_cr = 0.5, pt = 0.1, ap = 0.1)\n",
    "model1.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_final = [fit_model(X, y, m, pl = 0) for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model1.solution[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = [m.predict_proba(X) for m in models_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train_w = [preds_train[k] * weights[k] for k in range(len(weights))]\n",
    "probs_train_agg = np.sum(probs_train_w, axis = 0)\n",
    "y_train_hat = np.argmax(probs_train_agg, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y, y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = [m.predict_proba(X_test) for m in models_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_test_w = [preds_test[k] * weights[k] for k in range(len(weights))]\n",
    "probs_test_agg = np.sum(probs_test_w, axis = 0)\n",
    "y_test_hat = np.argmax(probs_test_agg, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test_data_w.csv\", y_test_hat, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
